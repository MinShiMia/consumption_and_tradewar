{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trade and Tariff Dataset at the County level\n",
    "\n",
    "This notebook constructs a trade and county-level tariff data, over time, dataset. **This is a core notebook to the project** so I will try and explain each step clearly. This is one aspect of my code to be scrutinized. It outputs the county-level trade and tariff dataset as a `.parquet` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd             # data package\n",
    "import matplotlib.pyplot as plt # graphics \n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "import requests, io             # internet and input tools  \n",
    "import zipfile as zf            # zip file tools \n",
    "import os  \n",
    "\n",
    "#import weightedcalcs as wc\n",
    "#import numpy as np\n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 Grab and manipulate the county level data for 2017\n",
    "\n",
    "So we will grab the single file, then adjust it to suit our needs. The needs are to construct county-level employment weights to create a trade exposure metric and tariff metric for each county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type of zipfile object: <class 'zipfile.ZipFile'>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3058: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>area_fips</th>\n",
       "      <th>own_code</th>\n",
       "      <th>industry_code</th>\n",
       "      <th>agglvl_code</th>\n",
       "      <th>size_code</th>\n",
       "      <th>year</th>\n",
       "      <th>disclosure_code</th>\n",
       "      <th>annual_avg_estabs</th>\n",
       "      <th>annual_avg_emplvl</th>\n",
       "      <th>total_annual_wages</th>\n",
       "      <th>avg_annual_pay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>50</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>124881</td>\n",
       "      <td>1936819</td>\n",
       "      <td>89088710816</td>\n",
       "      <td>45997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>51</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1208</td>\n",
       "      <td>53131</td>\n",
       "      <td>4339038631</td>\n",
       "      <td>81668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>52</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1208</td>\n",
       "      <td>53131</td>\n",
       "      <td>4339038631</td>\n",
       "      <td>81668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1021</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>610</td>\n",
       "      <td>11173</td>\n",
       "      <td>716001109</td>\n",
       "      <td>64083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>1022</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>2017</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>369309</td>\n",
       "      <td>30354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  area_fips  own_code industry_code  agglvl_code  size_code  year  \\\n",
       "0      1000         0            10           50          0  2017   \n",
       "1      1000         1            10           51          0  2017   \n",
       "2      1000         1           102           52          0  2017   \n",
       "3      1000         1          1021           53          0  2017   \n",
       "4      1000         1          1022           53          0  2017   \n",
       "\n",
       "  disclosure_code  annual_avg_estabs  annual_avg_emplvl  total_annual_wages  \\\n",
       "0             NaN             124881            1936819         89088710816   \n",
       "1             NaN               1208              53131          4339038631   \n",
       "2             NaN               1208              53131          4339038631   \n",
       "3             NaN                610              11173           716001109   \n",
       "4             NaN                  2                 12              369309   \n",
       "\n",
       "   avg_annual_pay  \n",
       "0           45997  \n",
       "1           81668  \n",
       "2           81668  \n",
       "3           64083  \n",
       "4           30354  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://data.bls.gov/cew/data/files/2017/csv/2017_annual_singlefile.zip\"\n",
    "# This will read in the annual, single file. It's big, but has all we want...\n",
    "\n",
    "r = requests.get(url) \n",
    "\n",
    "# convert bytes to zip file  \n",
    "bls_sf = zf.ZipFile(io.BytesIO(r.content)) \n",
    "print('Type of zipfile object:', type(bls_sf))\n",
    "\n",
    "clist = ['area_fips', 'own_code', 'industry_code', 'agglvl_code', 'size_code',\n",
    "       'year', 'disclosure_code', 'annual_avg_estabs',\n",
    "       'annual_avg_emplvl', 'total_annual_wages','avg_annual_pay']\n",
    "\n",
    "df = pd.read_csv(bls_sf.open(bls_sf.namelist()[0]), usecols= clist)\n",
    "\n",
    "# SHOULD PRESPECIFY TYPES TO \n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then the file below cleans stuff up. The most important is the `NAICS_county_level` which selects the NAICS aggregation and then the county aggregation. Website describing this is here:\n",
    "\n",
    "[https://data.bls.gov/cew/doc/titles/agglevel/agglevel_titles.htm](https://data.bls.gov/cew/doc/titles/agglevel/agglevel_titles.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NAICS_county_level = 75 \n",
    "# This is the code that will select only counties at the 3 digit NAICS level\n",
    "\n",
    "df_county = df[df.agglvl_code == NAICS_county_level].copy()\n",
    "\n",
    "df_county = df_county[df_county.own_code == 5]\n",
    "# Only grab private stuff\n",
    "\n",
    "df_county = df_county[(df_county.area_fips.str[0:2] != \"72\") & (df_county.area_fips.str[0:2] != \"78\")\n",
    "              & (df_county.area_fips.str[0:2] != \"02\") & (df_county.area_fips.str[0:2] != \"15\")]\n",
    "#Drop puerto rico, alaska, hawaii...this mayb not be doing what I think it is...as it looks like these guys are there\n",
    "# Does not matter as analysis is performed withthem, drop them when do the map. \n",
    "\n",
    "df_county[\"sup_ind\"] = df_county.industry_code.str[1].astype(int)\n",
    "# sometimes there are super industries floating around we want to drop them.\n",
    "# not clear if this matters with the conditioning all ready\n",
    "\n",
    "df_county = df_county[df_county[\"sup_ind\"] > 0]\n",
    "\n",
    "df_county.area_fips = df_county.area_fips.astype(str)\n",
    "\n",
    "df_national = df_county.groupby(\"industry_code\").agg({\"annual_avg_emplvl\": \"sum\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_national.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_national.rename({\"annual_avg_emplvl\":\"nat_emplvl\"}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>industry_code</th>\n",
       "      <th>nat_emplvl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>534697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>112</td>\n",
       "      <td>228471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>113</td>\n",
       "      <td>45166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>114</td>\n",
       "      <td>5005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>115</td>\n",
       "      <td>352957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  industry_code  nat_emplvl\n",
       "0           111      534697\n",
       "1           112      228471\n",
       "2           113       45166\n",
       "3           114        5005\n",
       "4           115      352957"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_national.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute annual employment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115756851"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_county.annual_avg_emplvl.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which matches well with FRED (https://fred.stlouisfed.org/series/USPRIV) in 2017 (off by a couple million)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 2 Bring in the trade data\n",
    "\n",
    "Here we will read in data at the HS6 level, exports to china, over time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_COMMODITY</th>\n",
       "      <th>CTY_CODE</th>\n",
       "      <th>ALL_VAL_MO</th>\n",
       "      <th>CTY_NAME</th>\n",
       "      <th>time</th>\n",
       "      <th>COMM_LVL</th>\n",
       "      <th>CTY_CODE</th>\n",
       "      <th>china_trade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>117508</td>\n",
       "      <td>852692</td>\n",
       "      <td>5700</td>\n",
       "      <td>3679920</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>HS6</td>\n",
       "      <td>5700</td>\n",
       "      <td>3679920.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117509</td>\n",
       "      <td>852713</td>\n",
       "      <td>5700</td>\n",
       "      <td>166946</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>HS6</td>\n",
       "      <td>5700</td>\n",
       "      <td>166946.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117510</td>\n",
       "      <td>852719</td>\n",
       "      <td>5700</td>\n",
       "      <td>0</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>HS6</td>\n",
       "      <td>5700</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117511</td>\n",
       "      <td>852721</td>\n",
       "      <td>5700</td>\n",
       "      <td>58483</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>HS6</td>\n",
       "      <td>5700</td>\n",
       "      <td>58483.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117512</td>\n",
       "      <td>852729</td>\n",
       "      <td>5700</td>\n",
       "      <td>0</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>HS6</td>\n",
       "      <td>5700</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117513</td>\n",
       "      <td>852791</td>\n",
       "      <td>5700</td>\n",
       "      <td>105003</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>HS6</td>\n",
       "      <td>5700</td>\n",
       "      <td>105003.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117514</td>\n",
       "      <td>852799</td>\n",
       "      <td>5700</td>\n",
       "      <td>38370</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>HS6</td>\n",
       "      <td>5700</td>\n",
       "      <td>38370.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117515</td>\n",
       "      <td>852842</td>\n",
       "      <td>5700</td>\n",
       "      <td>5395</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>HS6</td>\n",
       "      <td>5700</td>\n",
       "      <td>5395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117516</td>\n",
       "      <td>852849</td>\n",
       "      <td>5700</td>\n",
       "      <td>0</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>HS6</td>\n",
       "      <td>5700</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117517</td>\n",
       "      <td>852852</td>\n",
       "      <td>5700</td>\n",
       "      <td>1037134</td>\n",
       "      <td>CHINA</td>\n",
       "      <td>2019-07-01</td>\n",
       "      <td>HS6</td>\n",
       "      <td>5700</td>\n",
       "      <td>1037134.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       E_COMMODITY CTY_CODE ALL_VAL_MO CTY_NAME       time COMM_LVL CTY_CODE  \\\n",
       "117508      852692     5700    3679920    CHINA 2019-07-01      HS6     5700   \n",
       "117509      852713     5700     166946    CHINA 2019-07-01      HS6     5700   \n",
       "117510      852719     5700          0    CHINA 2019-07-01      HS6     5700   \n",
       "117511      852721     5700      58483    CHINA 2019-07-01      HS6     5700   \n",
       "117512      852729     5700          0    CHINA 2019-07-01      HS6     5700   \n",
       "117513      852791     5700     105003    CHINA 2019-07-01      HS6     5700   \n",
       "117514      852799     5700      38370    CHINA 2019-07-01      HS6     5700   \n",
       "117515      852842     5700       5395    CHINA 2019-07-01      HS6     5700   \n",
       "117516      852849     5700          0    CHINA 2019-07-01      HS6     5700   \n",
       "117517      852852     5700    1037134    CHINA 2019-07-01      HS6     5700   \n",
       "\n",
       "        china_trade  \n",
       "117508    3679920.0  \n",
       "117509     166946.0  \n",
       "117510          0.0  \n",
       "117511      58483.0  \n",
       "117512          0.0  \n",
       "117513     105003.0  \n",
       "117514      38370.0  \n",
       "117515       5395.0  \n",
       "117516          0.0  \n",
       "117517    1037134.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_key = \"&key=34e40301bda77077e24c859c6c6c0b721ad73fc7\"\n",
    "# This is my key. I'm nice and I have it posted. If you will be doing more with this\n",
    "# please get your own key!\n",
    "\n",
    "end_use = \"hs?get=E_COMMODITY,CTY_CODE,ALL_VAL_MO,CTY_NAME\"\n",
    "\n",
    "url = \"https://api.census.gov/data/timeseries/intltrade/exports/\" + end_use \n",
    "url = url + my_key + \"&time==from+2017-01\" + \"&COMM_LVL=HS6\"\n",
    "\n",
    "url = url + \"&CTY_CODE=5700\"\n",
    "\n",
    "r = requests.get(url) \n",
    "\n",
    "df_china_trade = pd.DataFrame(r.json()[1:]) # This then converts it to a dataframe\n",
    "# Note that the first entry is the labels\n",
    "\n",
    "df_china_trade.columns = r.json()[0]\n",
    "\n",
    "df_china_trade.time = pd.to_datetime(df_china_trade.time, format=\"%Y-%m\")\n",
    "# This is so I can call this correctly...\n",
    "\n",
    "df_china_trade[\"china_trade\"] = df_china_trade.ALL_VAL_MO.astype(float)\n",
    "\n",
    "df_china_trade.E_COMMODITY = df_china_trade.E_COMMODITY.astype(str)\n",
    "\n",
    "df_china_trade.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now grab **total exports** (not just China) by HS6 level, overtime. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E_COMMODITY</th>\n",
       "      <th>ALL_VAL_MO</th>\n",
       "      <th>time</th>\n",
       "      <th>COMM_LVL</th>\n",
       "      <th>total_trade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>110813</td>\n",
       "      <td>554794</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>HS6</td>\n",
       "      <td>554794.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>843510</td>\n",
       "      <td>1005059</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HS6</td>\n",
       "      <td>1005059.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>845110</td>\n",
       "      <td>208731</td>\n",
       "      <td>2017-01-01</td>\n",
       "      <td>HS6</td>\n",
       "      <td>208731.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>843510</td>\n",
       "      <td>1162859</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>HS6</td>\n",
       "      <td>1162859.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>845110</td>\n",
       "      <td>79269</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>HS6</td>\n",
       "      <td>79269.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>110813</td>\n",
       "      <td>756103</td>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>HS6</td>\n",
       "      <td>756103.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>843510</td>\n",
       "      <td>1580693</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>HS6</td>\n",
       "      <td>1580693.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>845110</td>\n",
       "      <td>74130</td>\n",
       "      <td>2018-03-01</td>\n",
       "      <td>HS6</td>\n",
       "      <td>74130.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>110813</td>\n",
       "      <td>701378</td>\n",
       "      <td>2018-09-01</td>\n",
       "      <td>HS6</td>\n",
       "      <td>701378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>110813</td>\n",
       "      <td>785645</td>\n",
       "      <td>2019-05-01</td>\n",
       "      <td>HS6</td>\n",
       "      <td>785645.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  E_COMMODITY ALL_VAL_MO       time COMM_LVL  total_trade\n",
       "0      110813     554794 2018-01-01      HS6     554794.0\n",
       "1      843510    1005059 2017-01-01      HS6    1005059.0\n",
       "2      845110     208731 2017-01-01      HS6     208731.0\n",
       "3      843510    1162859 2018-01-01      HS6    1162859.0\n",
       "4      845110      79269 2018-01-01      HS6      79269.0\n",
       "5      110813     756103 2019-02-01      HS6     756103.0\n",
       "6      843510    1580693 2018-03-01      HS6    1580693.0\n",
       "7      845110      74130 2018-03-01      HS6      74130.0\n",
       "8      110813     701378 2018-09-01      HS6     701378.0\n",
       "9      110813     785645 2019-05-01      HS6     785645.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "end_use = \"hs?get=E_COMMODITY,ALL_VAL_MO\"\n",
    "\n",
    "url = \"https://api.census.gov/data/timeseries/intltrade/exports/\"\n",
    "url = url + end_use + my_key + \"&time==from+2017-01\" + \"&COMM_LVL=HS6\"\n",
    "\n",
    "r = requests.get(url) \n",
    "\n",
    "df_all_trade = pd.DataFrame(r.json()[1:]) # This then converts it to a dataframe\n",
    "# Note that the first entry is the labels\n",
    "\n",
    "df_all_trade.columns = r.json()[0]\n",
    "\n",
    "df_all_trade.time = pd.to_datetime(df_all_trade.time, format=\"%Y-%m\")\n",
    "# This is so I can call this correctly...\n",
    "\n",
    "df_all_trade[\"total_trade\"] = df_all_trade.ALL_VAL_MO.astype(float)\n",
    "\n",
    "df_all_trade.E_COMMODITY = df_all_trade.E_COMMODITY.astype(str)\n",
    "\n",
    "df_all_trade.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then combine the china trade and the all trade dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrade = df_all_trade.merge(df_china_trade[[\"E_COMMODITY\", \"time\",\"china_trade\"]], left_on = [\"E_COMMODITY\", \"time\"], \n",
    "                             right_on = [\"E_COMMODITY\", \"time\"], how = \"left\")\n",
    "\n",
    "dftrade.set_index(\"time\", inplace = True)\n",
    "\n",
    "dftrade.drop([\"ALL_VAL_MO\"], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 3 Bring in concordance, create annual and national data set.\n",
    "\n",
    "Assign Naics codes, create a annual 2017 `df`, create the trade wieghts by naics so we can aggregate the tariffs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrade_17 = dftrade.loc[\"2017\"].groupby(\"E_COMMODITY\").agg({\"china_trade\":\"sum\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the concordance from the US Census to go from HS6 to NAICS. In the code below there are two different approaches to working with the concordance. The latter one makes more sense. Ultimatly does not matter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"https://www.census.gov/foreign-trade/reference/codes/concordance/expconcord17.xls\"\n",
    "\n",
    "#df_concordance = pd.read_excel(url, dtype = {\"commodity\": str, \"naics\": str})\n",
    "\n",
    "#df_concordance[\"hs8\"] = df_concordance.commodity.str[0:8]\n",
    "# truncate down to get the hs8\n",
    "\n",
    "#df_concordance[\"hs6\"] = df_concordance.commodity.str[0:6]\n",
    "# truncate down to get the hs6\n",
    "\n",
    "#df_concordance[\"naics3\"] = df_concordance[\"naics\"].str[0:3]\n",
    "\n",
    "#dict_concordance = dict(zip(df_concordance.hs6,df_concordance.naics)) \n",
    "\n",
    "# This creates a dictionaty from which we can map the hs6 to the naics codes\n",
    "\n",
    "# Full disclosure. There is an issue with the creation of the dictionary as a unique \n",
    "# mapping from hs6 to naics. The notebook ``alt_hs_naics_mapping.ipynb'' provides a complete discussion.\n",
    "# Ultimatly, this does not matter for the results (relative to the alternative below)\n",
    "\n",
    "# Below is a fix/alternative approach to creating the mapping from hs6 to naics. In the\n",
    "# cases where there are multiple naics codes for each hs6 code, it assigns the naics code that is\n",
    "# associated with the most trade. \n",
    "\n",
    "file_path = os.getcwd()\n",
    "\n",
    "alt_concordance = pq.read_table(file_path + \"\\\\data\\\\alt_concordance.parquet\").to_pandas()\n",
    "\n",
    "alt_concordance.head()\n",
    "\n",
    "dict_concordance = dict(zip(alt_concordance.hs6,alt_concordance.naics)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create this at different levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrade_17[\"hs6\"] = dftrade_17.index\n",
    "\n",
    "dftrade_17[\"naics\"] = dftrade_17[\"hs6\"].map(dict_concordance)\n",
    "\n",
    "dftrade_17[\"naics4\"] = dftrade_17[\"naics\"].str[0:4]\n",
    "\n",
    "dftrade_17[\"naics3\"] = dftrade_17[\"naics\"].str[0:3]\n",
    "\n",
    "dftrade_17.rename({\"china_trade\":\"2017_china_trade\"}, axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrade_17.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This look good, we have the commodity (as the index), chinese trade, and then different codes to map stuff to. \n",
    "\n",
    "Here we will work at the NAICS 3 digit level. The rational for this is that if you go more disaggregate, then confidentialy issues lead to employment at the county-level to be drpoed from the QECW. This is just a simple ``.groupby`` operation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrade_17_naics3 = dftrade_17.groupby(\"naics3\").agg({\"2017_china_trade\": \"sum\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrade_17_naics3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now merge this with the national employment by naics data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_national = df_national.merge(dftrade_17_naics3[\"2017_china_trade\"],\n",
    "                                left_on = \"industry_code\", right_index = True, how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_national[\"2017_china_trade\"].replace(np.nan, 0, inplace = True)\n",
    "\n",
    "df_national[\"trd_wts\"] = (df_national[\"2017_china_trade\"]/df_national[\"2017_china_trade\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then check to make sure that the trade weights sum up to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_national.trd_wts.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrade[\"hs6\"] = dftrade.E_COMMODITY\n",
    "\n",
    "dftrade[\"naics\"] = dftrade[\"hs6\"].map(dict_concordance)\n",
    "\n",
    "dftrade[\"naics4\"] = dftrade[\"naics\"].str[0:4]\n",
    "\n",
    "dftrade[\"naics3\"] = dftrade[\"naics\"].str[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Step 4 Add in the tariff data...\n",
    "\n",
    "Now here is one of the harder parts.\n",
    "\n",
    "We want to take the time series data, then layer on the tariff data by product and time. So we will have a big data frame that is (at HS6 level) over time, but each unit of observation has the associated 2017 annual value and the tariff at that date. \n",
    "\n",
    "So we will use the `map` function to exploit this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tariffs = pd.read_csv(\"tariff_list_naics.csv\", dtype = {\"HS-8 code\": str,\"HS6\": str,\"naics\": str,\"naics4\": str})\n",
    "\n",
    "file_path = os.getcwd() + \"\\\\data\"\n",
    "\n",
    "# bring in the tariff data\n",
    "\n",
    "tariffs = pd.read_csv(file_path + \"\\\\new_tariff_list_max.csv\", dtype = {\"hs6\": str})\n",
    "# This is the tariff dataset created by updated_tariff_data.ipynb (note the max tariff means taking the largest value\n",
    "# when going from Chinese hs10 to hs6. This does not matter, if anything gives more conservative resutls)\n",
    "\n",
    "tariffs.time_of_tariff = pd.to_datetime(tariffs.time_of_tariff, format=\"%Y-%m\")\n",
    "# make sure the time is there.\n",
    "\n",
    "tariffs.set_index(\"time_of_tariff\",inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tariffs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we create dictionaries to do the following \" you tell me HS, I tell you tariff\" by time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_tariff = dict(zip(tariffs.loc[\"2018-01-01\"].hs6,tariffs.loc[\"2018-01-01\"].tariff)) \n",
    "# These are the initial mfn tariffs. We will apply these from 2017 up untill the changes...\n",
    "\n",
    "tariff_dict_232 = dict(zip(tariffs.loc[\"2018-04-02\"].hs6,tariffs.loc[\"2018-04-02\"].tariff)) \n",
    "#These are the section 232 tariffs, response to US steel and aluminum. \n",
    "\n",
    "tariff_dict_r1 = dict(zip(tariffs.loc[\"2018-07-06\"].hs6,tariffs.loc[\"2018-07-06\"].tariff)) \n",
    "#tariff_dict_r1 = dict(zip(tariffs.loc[\"2018-07-06\"].HS6,tariffs.loc[\"2018-07-06\"].tariff)) \n",
    "# This will create a mapping from HS6 to tariff, you tell me HS, I tell you tariff\n",
    "\n",
    "tariff_dict_r2 = dict(zip(tariffs.loc[dt.datetime(2018,8,23)].hs6,tariffs.loc[dt.datetime(2018,8,23)].tariff)) \n",
    "\n",
    "#tariff_dict_r2 = dict(zip(tariffs.loc[dt.datetime(2018,8,23)].HS6,tariffs.loc[dt.datetime(2018,8,23)].tariff)) \n",
    "# This will create a mapping from HS6 to tariff, you tell me HS, I tell you tariff, round 2\n",
    "\n",
    "tariff_dict_r3 = dict(zip(tariffs.loc[dt.datetime(2018,9,24)].hs6,tariffs.loc[dt.datetime(2018,9,24)].tariff))\n",
    "#tariff_dict_r3 = dict(zip(tariffs.loc[dt.datetime(2018,9,24)].HS6,tariffs.loc[dt.datetime(2018,9,24)].tariff)) \n",
    "# This will create a mapping from HS6 to tariff, you tell me HS, I tell you tariff, round 3\n",
    "\n",
    "tariff_dict_mfn = dict(zip(tariffs.loc[\"2018-11-01\"].hs6,tariffs.loc[\"2018-11-01\"].tariff))\n",
    "# This reflects mfn adjustments that China made later in the year.\n",
    "\n",
    "tariff_dict_mfn_2019 = dict(zip(tariffs.loc[\"2019-01-02\"].hs6,tariffs.loc[\"2019-01-02\"].tariff))\n",
    "# This reflects mfn adjustments and auto adjustment China made at the start of 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then assign the tariffs to the hs6 codes. As mentioned below, the ``.update`` function updates the product code with a new tariff if there is one in the new dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrade[\"tariff\"] = 0\n",
    "\n",
    "# Then use the map function which will fill in the tariff in the correct places..\n",
    "# Note the key issue was that the dictionaries were overwritting stuff, hence\n",
    "# the update...\n",
    "\n",
    "# Start with the MFN...\n",
    "dftrade.loc[\"2017-01\":,\"tariff\"] = dftrade.loc[\"2017-01\":,\"hs6\"].map(initial_tariff)\n",
    "\n",
    "#print(\"done\")\n",
    "# Now update given the 232 response\n",
    "initial_tariff.update(tariff_dict_232)\n",
    "\n",
    "dftrade.loc[\"2018-04\":,\"tariff\"] = dftrade.loc[\"2018-04\":,\"hs6\"].map(initial_tariff)\n",
    "\n",
    "#print(\"done\")\n",
    "# This is the big Phase 1 of the war\n",
    "initial_tariff.update(tariff_dict_r1)\n",
    "\n",
    "dftrade.loc[\"2018-07\":,\"tariff\"] = dftrade.loc[\"2018-07\":,\"hs6\"].map(initial_tariff)\n",
    "\n",
    "#print(\"done\")\n",
    "# Here is phase 2\n",
    "initial_tariff.update(tariff_dict_r2)\n",
    "\n",
    "dftrade.loc[\"2018-09\":,\"tariff\"] = dftrade.loc[\"2018-09\":,\"hs6\"].map(initial_tariff)\n",
    "\n",
    "#print(\"done\")\n",
    "# Here is phase 3\n",
    "initial_tariff.update(tariff_dict_r3)\n",
    "\n",
    "dftrade.loc[\"2018-10\":,\"tariff\"] = dftrade.loc[\"2018-10\":,\"hs6\"].map(initial_tariff)\n",
    "\n",
    "#print(\"done\")\n",
    "# China then adjusts the mfn\n",
    "initial_tariff.update(tariff_dict_mfn)\n",
    "\n",
    "dftrade.loc[\"2018-11\":,\"tariff\"] = dftrade.loc[\"2018-11\":,\"hs6\"].map(initial_tariff)\n",
    "\n",
    "#print(\"done\")\n",
    "# An update on the mfn's\n",
    "initial_tariff.update(tariff_dict_mfn_2019)\n",
    "\n",
    "dftrade.loc[\"2019-01\":,\"tariff\"] = dftrade.loc[\"2019-01\":,\"hs6\"].map(initial_tariff)\n",
    "\n",
    "dftrade[\"tariff\"] = dftrade[\"tariff\"].replace(np.nan,0)\n",
    "\n",
    "dftrade[dftrade[\"tariff\"] == 25].head()\n",
    "\n",
    "dftrade[\"2018-08\"].head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is looking good, not how you can see the tariffs (in august of 2018) hitting in the right places.\n",
    "\n",
    "Now merge it with the 2017 annual trade data so we can construct trade weighted averages of tariffs...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrade = dftrade.merge(dftrade_17[\"2017_china_trade\"], how = \"inner\", left_on = \"E_COMMODITY\", right_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrade[dftrade.naics3 == \"111\"].sort_values(by = [\"tariff\"], ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we accomplished this task.\n",
    "\n",
    "Now what we will do is create a function which will make the trade weighted verage of the tariff rates as we aggregate across product codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trd_weighted_avg(df):\n",
    "    # A function to create the trade weighted average of the tariff rates\n",
    "    # by round...\n",
    "    \n",
    "    trd_w_avg = df[\"tariff\"].multiply(df[\"2017_china_trade\"],axis = 0).sum() \n",
    "    # here wuse the 2017 annual values to weight it\n",
    "    \n",
    "    trd_w_avg = trd_w_avg / df[\"2017_china_trade\"].sum()\n",
    "    \n",
    "    \n",
    "    foo = {\"tariff_trd_w_avg\": [trd_w_avg ], \n",
    "           \"total_trade\": df[\"total_trade\"].sum(),\n",
    "          \"china_trade\" : df[\"china_trade\"].sum()}\n",
    "    \n",
    "    return pd.DataFrame(foo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, `groupby` time and NAICS code (in this case 3), apply the trade weighted function above. Then the resulting data frame should be time, and naics tariffs and the total trade. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = dftrade.groupby([\"time\",\"naics3\"])\n",
    "\n",
    "exp_trf_bynaics = grp.apply(trd_weighted_avg)\n",
    "\n",
    "exp_trf_bynaics = exp_trf_bynaics.droplevel(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_trf_bynaics.loc[\"2018-01\"].head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_trf_bynaics.groupby([\"time\"]).agg({\"tariff_trd_w_avg\": \"mean\"}).plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This simple plot looks a lot like the Bowen figures. Note that the dip is all about China changing their MFN tariffs in (what appears to be) certain consumer orinted catagories as Bowen point out. So clothing stuff falls, while they are hammering the ag. products. \n",
    "\n",
    "Looks like we accomplished this task. Just a couple of things to clean up then we are ready to move onto the next step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_trf_bynaics[\"time\"] = exp_trf_bynaics.index.get_level_values(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_trf_bynaics = exp_trf_bynaics.droplevel(level=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_trf_bynaics.loc[\"111\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Step 3 Merge trade data with the county data\n",
    "\n",
    "This is the most time consuming step (interms of compuation time). So start with the county data set, `groupby` county, then apply a function which will create (i) time varying exports (which are constructed with the 2017 weightes) and (ii) time varying tariffs (also constructed using the 2017) weights. \n",
    "\n",
    "The final want is a big dataframe that has county, time, export exposure and tariff exposure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grp = df_county.groupby(\"area_fips\")\n",
    "\n",
    "# This creates groups at the county level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's just look at one of the groups...\n",
    "\n",
    "grp.get_group(\"1001\").head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below are the two key functions that deliver this. Basically it does the following: \n",
    "\n",
    "- Take a group at county level, merge it with the national level data set, so the resulting `df` has the county and nation.\n",
    "\n",
    "- Create the weights. \n",
    "\n",
    "- Then merge it with the exports, this will now be a df with exports varying over time, but with the fixed weights associated with each entry.\n",
    "\n",
    "- Then aggregate the national exports by NAICS by the county level weights, giving a county level time series of exports.\n",
    "\n",
    "---\n",
    "\n",
    "**Updates**\n",
    "\n",
    "- The tariff measure does the following: fix a county, take employment in industry $i$ and divide by total county employment, then sum up tariffs across industries with the weights being the county level share. The idea here is if all employment in a county is soy, then the \"effective\" tariff that the county faces is the soy tariff.\n",
    "\n",
    "In equation terms: here $c$ is county, $s$ is industry, $n$, below is nation.\n",
    "\n",
    "$\\tau_{c,t} = \\sum_{s\\in S}\\frac{L_{c,s}}{L_{c,S}} \\tau_{s,t}$\n",
    "\n",
    "Note that below, I make one further adjustment to make sure that $L_{c,S}$ is for all employment, not just the sum across $L_{c,s}$\n",
    "\n",
    "\n",
    "- The export measure: What am I doing: take a county's employment in industry $i$ and divide by **national** level employment in industry $i$. Then a \"county's\" exports is the the sum across industries, weighted by the county's share of national employment in each industry. The idea here is, if a county's has all national level employment in an industry, all that industries exports will be assigned to that county.\n",
    "\n",
    "$\\mbox{EX}_{c,t} = \\frac{1}{L_{c,S,2017}}\\sum_{s\\in S}\\frac{L_{c,s,2017}}{L_{n,s,2017}} \\mbox{EX}_{s,t}$\n",
    "\n",
    "and then I divide by total employment in the county to have a county per worker measure. This is done for exports to China and then export in total. Note that below, I make one further adjustment to make sure that $L_{c,S}$ is for all employment, not just the sum across $L_{c,s}$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_trade_weights(df):\n",
    "    # Takes in the county groupings and will return, for each county, a time series of export\n",
    "    # exposure, tariffs, and other statistics. \n",
    "\n",
    "    new_df = df.merge(df_national[[\"nat_emplvl\",\n",
    "                                   \"industry_code\", \"trd_wts\"]],\n",
    "                                  how = \"outer\", left_on = \"industry_code\", right_on = \"industry_code\")\n",
    "    # Merge the nation with the county, why, we want to make sure all the naics codes are lined up properly\n",
    "        \n",
    "    new_df[\"emp_wts\"] = (new_df.annual_avg_emplvl/new_df.nat_emplvl)\n",
    "     \n",
    "    # create the weights...\n",
    "        \n",
    "    foo_df = exp_trf_bynaics.merge(new_df[[\"emp_wts\",\"trd_wts\",\n",
    "                                           \"industry_code\",\n",
    "                                          \"annual_avg_emplvl\"]], left_index = True, right_on = \"industry_code\")  \n",
    "    \n",
    "    # Now each weight is for a NAICS code, we will merge it with the export trade data set, so for all naics, all time...\n",
    "    # This is a big df whith all trade data and then the county's weights for each naics code\n",
    "    \n",
    "    foo_grp = foo_df.groupby(\"time\")\n",
    "    \n",
    "    # group by time. \n",
    "    \n",
    "    foo = foo_grp.apply(trade_by_naics)\n",
    "    \n",
    "    # Then for each time gropuing, we aggregate across the naics codes according to the weights above.\n",
    "    \n",
    "    foo = foo.droplevel(1)\n",
    "    \n",
    "    foo[\"fips\"] = df[\"area_fips\"].astype(str).iloc[0]\n",
    "    \n",
    "    # some cleaning of the df\n",
    "    \n",
    "    foo[\"total_employment\"] = new_df.annual_avg_emplvl.sum()\n",
    "    \n",
    "    # get total employment.\n",
    "    \n",
    "    return pd.DataFrame(foo)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trade_by_naics(df):\n",
    "    # Simple function just to test about aggregation \n",
    "\n",
    "    china_exp_pc = (1/df[\"annual_avg_emplvl\"].sum())*(df[\"china_trade\"]*df[\"emp_wts\"]).sum()\n",
    "    \n",
    "    total_exp_pc = (1/df[\"annual_avg_emplvl\"].sum())*(df[\"total_trade\"]*df[\"emp_wts\"]).sum()\n",
    "    # the first term multiplies trade by the county's share of national level employment\n",
    "    # then the outside term divides by number of workers in a county. \n",
    "    \n",
    "    #tariff_nwt_pc = (1/df[\"annual_avg_emplvl\"].sum())*(df[\"tariff_trd_w_avg\"]*df[\"emp_wts\"]).sum()\n",
    "    # This is the measure that makes most sense, need to justify it...\n",
    "    tariff =  ((df[\"annual_avg_emplvl\"]*df[\"tariff_trd_w_avg\"])/df[\"annual_avg_emplvl\"].sum()).sum()\n",
    "    # local employment share weighted tariff. So if all guys are in area are working in soy,\n",
    "    # then they are facing the soybean tariff....\n",
    "    \n",
    "    foo = {\"total_exp_pc\": [total_exp_pc],\n",
    "          \"china_exp_pc\": [china_exp_pc],\n",
    "           \"tariff\": [tariff],\n",
    "          \"emplvl_2017\": df[\"annual_avg_emplvl\"].sum()}\n",
    "\n",
    "    return pd.DataFrame(foo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then apply the function to the county groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_county = grp.apply(create_trade_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we are done and output the file to where we want it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_county.sort_values(by = [\"tariff\",\"emplvl_2017\"], ascending = False).head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**One more adjustment.** Notice that in the function, when we are merging, we are droping all the NAICS codes without trade. So these measures (total trade, china trade, and tariffs) are only conditional on being traded. This only matters in so far as the denominator, the ``df[\"annual_avg_emplvl\"].sum()`` is concerned. \n",
    "\n",
    "To make the adjustment then, we multiply the employment measure in the denominator and then divide through by the ``total_employment`` measure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_county[\"tariff\"] = (trade_county[\"emplvl_2017\"]/\n",
    "                              trade_county[\"total_employment\"])*trade_county[\"tariff\"]\n",
    "\n",
    "trade_county[\"china_exp_pc\"] = (trade_county[\"emplvl_2017\"]/\n",
    "                                    trade_county[\"total_employment\"])*trade_county[\"china_exp_pc\"]\n",
    "\n",
    "trade_county[\"total_exp_pc\"] = (trade_county[\"emplvl_2017\"]/\n",
    "                                    trade_county[\"total_employment\"])*trade_county[\"total_exp_pc\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.getcwd() + \"\\\\data\"+ \"\\\\total_trade_data.parquet\"\n",
    "\n",
    "pq.write_table(pa.Table.from_pandas(trade_county.reset_index()), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trade_county.sort_values(by = [\"tariff\",\"emplvl_2017\"], ascending = False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exposure = pd.qcut(trade_county.xs('2018-12-1', level=1).tariff, 4 ,labels = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_exposed = exposure[exposure == 3].index.tolist()\n",
    "\n",
    "trade_county.loc[most_exposed].xs('2018-12-1', level=1).tariff.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
