{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd             # data package\n",
    "import matplotlib.pyplot as plt # graphics \n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "import requests, io             # internet and input tools  \n",
    "import zipfile as zf            # zip file tools \n",
    "import os  \n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "from linearmodels.iv import IV2SLS\n",
    "from linearmodels.panel import PanelOLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview. \n",
    "\n",
    "This file essentially grabs the month by county files from the [Quarterly Census of Employment and Wages](https://www.bls.gov/cew/) files from the BLS and then creates employment measures at the county-level, monthly frequency. A couple of comments about the code:\n",
    "\n",
    "   - In the funciton ``clean_bls_quarter`` there is a line to be uncommented or not depending upon if I want a dataset with goods employment or total employment. Future enhancements of this notebook should just return one dataframe with both.\n",
    "    \n",
    "    \n",
    "   - It can accomadate the 2016 data (and further back if modified). Currently it just uses the 2017, 2018, and 2019 (which only have Q1 values. See the relese calander when updates will be made.\n",
    "   \n",
    "### Step 1\n",
    "\n",
    "Bring in the trade/tariff data for which we will merge stuff...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "trade_data = pq.read_table(cwd + \"\\\\data\\\\total_trade_data.parquet\").to_pandas()\n",
    "\n",
    "trade_data[\"time\"] = pd.to_datetime(trade_data.time)\n",
    "\n",
    "trade_data.set_index([\"area_fips\", \"time\"],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.515098948465189"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_data.head()\n",
    "\n",
    "exposure = pd.qcut(trade_data.xs('2018-12-1', level=1).tariff, 4 ,labels = False)\n",
    "\n",
    "most_exposed = exposure[exposure == 3].index.tolist()\n",
    "\n",
    "trade_data.loc[most_exposed].xs('2018-12-1', level=1).tariff.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is ultra-clunky. Should fix in the future. But it takes names (which is how the BLS files are written) and then will map them into a datatime value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl_time_dict_16 = {\"January Employment\":dt.datetime(2016,1,1),\n",
    "                 \"February Employment\":dt.datetime(2016,2,1),\n",
    "                 \"March Employment\":dt.datetime(2016,3,1),\n",
    "                 \"April Employment\":dt.datetime(2016,4,1),\n",
    "                 \"May Employment\":dt.datetime(2016,5,1),\n",
    "                 \"June Employment\":dt.datetime(2016,6,1),\n",
    "                 \"July Employment\":dt.datetime(2016,7,1),\n",
    "                 \"August Employment\":dt.datetime(2016,8,1),\n",
    "                 \"September Employment\":dt.datetime(2016,9,1),\n",
    "                 \"October Employment\":dt.datetime(2016,10,1),\n",
    "                 \"November Employment\":dt.datetime(2016,11,1),\n",
    "                 \"December Employment\":dt.datetime(2016,12,1),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl_time_dict_17 = {\"January Employment\":dt.datetime(2017,1,1),\n",
    "                 \"February Employment\":dt.datetime(2017,2,1),\n",
    "                 \"March Employment\":dt.datetime(2017,3,1),\n",
    "                 \"April Employment\":dt.datetime(2017,4,1),\n",
    "                 \"May Employment\":dt.datetime(2017,5,1),\n",
    "                 \"June Employment\":dt.datetime(2017,6,1),\n",
    "                 \"July Employment\":dt.datetime(2017,7,1),\n",
    "                 \"August Employment\":dt.datetime(2017,8,1),\n",
    "                 \"September Employment\":dt.datetime(2017,9,1),\n",
    "                 \"October Employment\":dt.datetime(2017,10,1),\n",
    "                 \"November Employment\":dt.datetime(2017,11,1),\n",
    "                 \"December Employment\":dt.datetime(2017,12,1),}\n",
    "\n",
    "empl_time_dict_18 = {\"January Employment\":dt.datetime(2018,1,1),\n",
    "                 \"February Employment\":dt.datetime(2018,2,1),\n",
    "                 \"March Employment\":dt.datetime(2018,3,1),\n",
    "                 \"April Employment\":dt.datetime(2018,4,1),\n",
    "                 \"May Employment\":dt.datetime(2018,5,1),\n",
    "                 \"June Employment\":dt.datetime(2018,6,1),\n",
    "                 \"July Employment\":dt.datetime(2018,7,1),\n",
    "                 \"August Employment\":dt.datetime(2018,8,1),\n",
    "                 \"September Employment\":dt.datetime(2018,9,1),\n",
    "                 \"October Employment\":dt.datetime(2018,10,1),\n",
    "                 \"November Employment\":dt.datetime(2018,11,1),\n",
    "                 \"December Employment\":dt.datetime(2018,12,1),}\n",
    "\n",
    "empl_time_dict_19 = {\"January Employment\":dt.datetime(2019,1,1),\n",
    "                 \"February Employment\":dt.datetime(2019,2,1),\n",
    "                 \"March Employment\":dt.datetime(2019,3,1),}\n",
    "\n",
    "clistQ1 = ['Area\\nCode','NAICS','Qtr','January Employment', 'February Employment',\n",
    "       'March Employment', 'Total Quarterly Wages', 'Average Weekly Wage','Own',\"Area Type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Download\n",
    "\n",
    "This downloads the ``.zip`` files for which we can grab the data. They are all in excell format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"https://data.bls.gov/cew/data/files/2016/xls/2016_all_county_high_level.zip\"\n",
    "# This will read in the annual, single file. It's big, but has all we want...\n",
    "\n",
    "#r = requests.get(url) \n",
    "\n",
    "# convert bytes to zip file  \n",
    "#bls_q2016 = zf.ZipFile(io.BytesIO(r.content)) \n",
    "#bls_q2016.extractall(cwd + \"\\\\bls_files\")\n",
    "\n",
    "url = \"https://data.bls.gov/cew/data/files/2017/xls/2017_all_county_high_level.zip\"\n",
    "# This will read in the annual, single file. It's big, but has all we want...\n",
    "\n",
    "r = requests.get(url) \n",
    "\n",
    "# convert bytes to zip file  \n",
    "bls_q2017 = zf.ZipFile(io.BytesIO(r.content)) \n",
    "bls_q2017.extractall(cwd + \"\\\\bls_files\")\n",
    "\n",
    "url = \"https://data.bls.gov/cew/data/files/2018/xls/2018_all_county_high_level.zip\"\n",
    "\n",
    "r = requests.get(url) \n",
    "\n",
    "bls_q2018 = zf.ZipFile(io.BytesIO(r.content)) \n",
    "bls_q2018.extractall(cwd + \"\\\\bls_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://data.bls.gov/cew/data/files/2019/xls/2019_all_county_high_level.zip\"\n",
    "\n",
    "r = requests.get(url) \n",
    "\n",
    "bls_q2019 = zf.ZipFile(io.BytesIO(r.content)) \n",
    "bls_q2019.extractall(cwd + \"\\\\bls_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ZipInfo filename='allhlcn191.xlsx' compress_type=deflate external_attr=0x20 file_size=6839716 compress_size=6715278>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bls_q2019.filelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### Step 3: Clean and Shape it\n",
    "   \n",
    "   Below is a function that takes in an excell sheet and does what we want to it. Then below we will work through a for loop over all the sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bls_quarter(excell_sheet, time_dict):\n",
    "\n",
    "    df = pd.read_excel(excell_sheet, sheet_name = \"US_St_Cn_MSA\")\n",
    "\n",
    "# Take only private\n",
    "\n",
    "    df = df[df[\"Own\"] == 5] \n",
    "\n",
    "# Take aggregate\n",
    "\n",
    "    #df = df[df[\"NAICS\"] == 101] # Take goods producing \n",
    "    \n",
    "    df = df[df[\"NAICS\"] == 10] # Take all employment in all sectors\n",
    "\n",
    "# Take only counties \n",
    "    df = df[df[\"Area Type\"] == \"County\"] \n",
    "\n",
    "    df.rename({\"Area\\nCode\": \"GEOFIPS\"},axis = 1, inplace = True)\n",
    "\n",
    "    df[\"GEOFIPS\"] = df[\"GEOFIPS\"].astype(int)\n",
    "\n",
    "    df.set_index(\"GEOFIPS\", inplace = True)\n",
    "\n",
    "    df = df.reindex(trade_data.index.get_level_values(0).unique().astype(int).tolist())\n",
    "\n",
    "    df = df.iloc[:,[13,14,15]].reset_index()\n",
    "    # This grabs only values we want, i.e. the employment for that quarter. So for example,\n",
    "    # in Q1, 13 = January, 14 = Febuary, 15 = March. And so forth for Q2...\n",
    "\n",
    "    df = df.melt(\"GEOFIPS\")\n",
    "\n",
    "    df.replace(time_dict,inplace = True)\n",
    "\n",
    "    df.rename({\"variable\":\"time\", \"value\":\"emply_month\", \"GEOFIPS\": \"area_fips\"}, axis = 1, inplace = True)\n",
    "    \n",
    "    df[\"area_fips\"] = df[\"area_fips\"].astype(str)\n",
    "    \n",
    "    df.set_index([\"area_fips\", \"time\"], inplace = True)\n",
    "    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then given the function above, work through the file list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_name = cwd + \"\\\\bls_files\\\\\"\n",
    "\n",
    "#root_name = root_name + \"allhlcn16\"\n",
    "\n",
    "#quarter = [\"1\",\"2\",\"3\",\"4\"]\n",
    "\n",
    "df = pd.DataFrame([])\n",
    "\n",
    "#for item in quarter:\n",
    "    \n",
    "#    file_name = root_name + item + \".xlsx\"\n",
    "    \n",
    "#    df = df.append(clean_bls_quarter(file_name,empl_time_dict_16))\n",
    "    \n",
    "############################################################################\n",
    "\n",
    "root_name = cwd + \"\\\\bls_files\\\\\"\n",
    "\n",
    "root_name = root_name + \"allhlcn17\"\n",
    "\n",
    "quarter = [\"1\",\"2\",\"3\",\"4\"]\n",
    "\n",
    "for item in quarter:\n",
    "    \n",
    "    file_name = root_name + item + \".xlsx\"\n",
    "    \n",
    "    df = df.append(clean_bls_quarter(file_name,empl_time_dict_17))\n",
    "    \n",
    "############################################################################  \n",
    "root_name = cwd + \"\\\\bls_files\\\\\"\n",
    "\n",
    "root_name = root_name + \"allhlcn18\"\n",
    "\n",
    "quarter = [\"1\",\"2\",\"3\",\"4\"]\n",
    "\n",
    "for item in quarter:\n",
    "    \n",
    "    file_name = root_name + item + \".xlsx\"\n",
    "    \n",
    "    df = df.append(clean_bls_quarter(file_name,empl_time_dict_18))\n",
    "    \n",
    "############################################################################  \n",
    "root_name = cwd + \"\\\\bls_files\\\\\"\n",
    "\n",
    "root_name = root_name + \"allhlcn19\"\n",
    "\n",
    "quarter = [\"1\"]\n",
    "\n",
    "for item in quarter:\n",
    "    \n",
    "    file_name = root_name + item + \".xlsx\"\n",
    "    \n",
    "    df = df.append(clean_bls_quarter(file_name,empl_time_dict_19))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then just checksome stuff, reshape, then save for the analysis part. Note how this is working (again clunky), if you want the goods employment, uncomment out that. If you want total employment do the other one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values([\"area_fips\", \"time\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_employ = trade_data.merge(df, left_index = True, right_index = True, how = \"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trade_employ.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = os.getcwd() + \"\\\\data\\\\trade_employment_goods.parquet\"\n",
    "\n",
    "#pq.write_table(pa.Table.from_pandas(trade_employ.reset_index()), file_path)\n",
    "\n",
    "file_path = os.getcwd() + \"\\\\data\\\\trade_employment_all.parquet\"\n",
    "\n",
    "pq.write_table(pa.Table.from_pandas(trade_employ.reset_index()), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_employ.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_employ.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
