{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\linearmodels\\panel\\data.py:10: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import (Categorical, DataFrame, Index, MultiIndex, Panel, Series,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd             # data package\n",
    "import matplotlib.pyplot as plt # graphics \n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "import requests, io             # internet and input tools  \n",
    "import zipfile as zf            # zip file tools \n",
    "import os  \n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "from linearmodels.iv import IV2SLS\n",
    "from linearmodels.panel import PanelOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "trade_data = pq.read_table(cwd + \"\\\\data\\\\total_trade_data.parquet\").to_pandas()\n",
    "\n",
    "trade_data[\"time\"] = pd.to_datetime(trade_data.time)\n",
    "\n",
    "trade_data.set_index([\"area_fips\", \"time\"],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.515098948465189"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_data.head()\n",
    "\n",
    "exposure = pd.qcut(trade_data.xs('2018-12-1', level=1).tariff, 4 ,labels = False)\n",
    "\n",
    "most_exposed = exposure[exposure == 3].index.tolist()\n",
    "\n",
    "trade_data.loc[most_exposed].xs('2018-12-1', level=1).tariff.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl_time_dict_16 = {\"January Employment\":dt.datetime(2016,1,1),\n",
    "                 \"February Employment\":dt.datetime(2016,2,1),\n",
    "                 \"March Employment\":dt.datetime(2016,3,1),\n",
    "                 \"April Employment\":dt.datetime(2016,4,1),\n",
    "                 \"May Employment\":dt.datetime(2016,5,1),\n",
    "                 \"June Employment\":dt.datetime(2016,6,1),\n",
    "                 \"July Employment\":dt.datetime(2016,7,1),\n",
    "                 \"August Employment\":dt.datetime(2016,8,1),\n",
    "                 \"September Employment\":dt.datetime(2016,9,1),\n",
    "                 \"October Employment\":dt.datetime(2016,10,1),\n",
    "                 \"November Employment\":dt.datetime(2016,11,1),\n",
    "                 \"December Employment\":dt.datetime(2016,12,1),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "empl_time_dict_17 = {\"January Employment\":dt.datetime(2017,1,1),\n",
    "                 \"February Employment\":dt.datetime(2017,2,1),\n",
    "                 \"March Employment\":dt.datetime(2017,3,1),\n",
    "                 \"April Employment\":dt.datetime(2017,4,1),\n",
    "                 \"May Employment\":dt.datetime(2017,5,1),\n",
    "                 \"June Employment\":dt.datetime(2017,6,1),\n",
    "                 \"July Employment\":dt.datetime(2017,7,1),\n",
    "                 \"August Employment\":dt.datetime(2017,8,1),\n",
    "                 \"September Employment\":dt.datetime(2017,9,1),\n",
    "                 \"October Employment\":dt.datetime(2017,10,1),\n",
    "                 \"November Employment\":dt.datetime(2017,11,1),\n",
    "                 \"December Employment\":dt.datetime(2017,12,1),}\n",
    "\n",
    "empl_time_dict_18 = {\"January Employment\":dt.datetime(2018,1,1),\n",
    "                 \"February Employment\":dt.datetime(2018,2,1),\n",
    "                 \"March Employment\":dt.datetime(2018,3,1),\n",
    "                 \"April Employment\":dt.datetime(2018,4,1),\n",
    "                 \"May Employment\":dt.datetime(2018,5,1),\n",
    "                 \"June Employment\":dt.datetime(2018,6,1),\n",
    "                 \"July Employment\":dt.datetime(2018,7,1),\n",
    "                 \"August Employment\":dt.datetime(2018,8,1),\n",
    "                 \"September Employment\":dt.datetime(2018,9,1),\n",
    "                 \"October Employment\":dt.datetime(2018,10,1),\n",
    "                 \"November Employment\":dt.datetime(2018,11,1),\n",
    "                 \"December Employment\":dt.datetime(2018,12,1),}\n",
    "\n",
    "empl_time_dict_19 = {\"January Employment\":dt.datetime(2019,1,1),\n",
    "                 \"February Employment\":dt.datetime(2019,2,1),\n",
    "                 \"March Employment\":dt.datetime(2019,3,1),}\n",
    "\n",
    "clistQ1 = ['Area\\nCode','NAICS','Qtr','January Employment', 'February Employment',\n",
    "       'March Employment', 'Total Quarterly Wages', 'Average Weekly Wage','Own',\"Area Type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#url = \"https://data.bls.gov/cew/data/files/2016/xls/2016_all_county_high_level.zip\"\n",
    "# This will read in the annual, single file. It's big, but has all we want...\n",
    "\n",
    "#r = requests.get(url) \n",
    "\n",
    "# convert bytes to zip file  \n",
    "#bls_q2016 = zf.ZipFile(io.BytesIO(r.content)) \n",
    "#bls_q2016.extractall(cwd + \"\\\\bls_files\")\n",
    "\n",
    "url = \"https://data.bls.gov/cew/data/files/2017/xls/2017_all_county_high_level.zip\"\n",
    "# This will read in the annual, single file. It's big, but has all we want...\n",
    "\n",
    "r = requests.get(url) \n",
    "\n",
    "# convert bytes to zip file  \n",
    "bls_q2017 = zf.ZipFile(io.BytesIO(r.content)) \n",
    "bls_q2017.extractall(cwd + \"\\\\bls_files\")\n",
    "\n",
    "url = \"https://data.bls.gov/cew/data/files/2018/xls/2018_all_county_high_level.zip\"\n",
    "\n",
    "r = requests.get(url) \n",
    "\n",
    "bls_q2018 = zf.ZipFile(io.BytesIO(r.content)) \n",
    "bls_q2018.extractall(cwd + \"\\\\bls_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://data.bls.gov/cew/data/files/2019/xls/2019_all_county_high_level.zip\"\n",
    "\n",
    "r = requests.get(url) \n",
    "\n",
    "bls_q2019 = zf.ZipFile(io.BytesIO(r.content)) \n",
    "bls_q2019.extractall(cwd + \"\\\\bls_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ZipInfo filename='allhlcn191.xlsx' compress_type=deflate external_attr=0x20 file_size=6839716 compress_size=6715278>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bls_q2019.filelist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bls_quarter(excell_sheet, time_dict):\n",
    "\n",
    "    df = pd.read_excel(excell_sheet, sheet_name = \"US_St_Cn_MSA\")\n",
    "\n",
    "# Take only private\n",
    "\n",
    "    df = df[df[\"Own\"] == 5] \n",
    "\n",
    "# Take aggregate\n",
    "\n",
    "    #df = df[df[\"NAICS\"] == 101] # Take goods producing \n",
    "    \n",
    "    df = df[df[\"NAICS\"] == 10] # Take all employment in all sectors\n",
    "\n",
    "# Take only counties \n",
    "    df = df[df[\"Area Type\"] == \"County\"] \n",
    "\n",
    "    df.rename({\"Area\\nCode\": \"GEOFIPS\"},axis = 1, inplace = True)\n",
    "\n",
    "    df[\"GEOFIPS\"] = df[\"GEOFIPS\"].astype(int)\n",
    "\n",
    "    df.set_index(\"GEOFIPS\", inplace = True)\n",
    "\n",
    "    df = df.reindex(trade_data.index.get_level_values(0).unique().astype(int).tolist())\n",
    "\n",
    "    df = df.iloc[:,[13,14,15]].reset_index()\n",
    "\n",
    "    df = df.melt(\"GEOFIPS\")\n",
    "\n",
    "    df.replace(time_dict,inplace = True)\n",
    "\n",
    "    df.rename({\"variable\":\"time\", \"value\":\"emply_month\", \"GEOFIPS\": \"area_fips\"}, axis = 1, inplace = True)\n",
    "    \n",
    "    df[\"area_fips\"] = df[\"area_fips\"].astype(str)\n",
    "    \n",
    "    df.set_index([\"area_fips\", \"time\"], inplace = True)\n",
    "    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#root_name = cwd + \"\\\\bls_files\\\\\"\n",
    "\n",
    "#root_name = root_name + \"allhlcn17\"\n",
    "\n",
    "#quarter = [\"1\",\"2\",\"3\",\"4\"]\n",
    "\n",
    "df = pd.DataFrame([])\n",
    "\n",
    "#for item in quarter:\n",
    "    \n",
    "#    file_name = root_name + item + \".xlsx\"\n",
    "    \n",
    "#    df = df.append(clean_bls_quarter(file_name,empl_time_dict_16))\n",
    "    \n",
    "############################################################################\n",
    "\n",
    "root_name = cwd + \"\\\\bls_files\\\\\"\n",
    "\n",
    "root_name = root_name + \"allhlcn17\"\n",
    "\n",
    "quarter = [\"1\",\"2\",\"3\",\"4\"]\n",
    "\n",
    "for item in quarter:\n",
    "    \n",
    "    file_name = root_name + item + \".xlsx\"\n",
    "    \n",
    "    df = df.append(clean_bls_quarter(file_name,empl_time_dict_17))\n",
    "    \n",
    "############################################################################  \n",
    "root_name = cwd + \"\\\\bls_files\\\\\"\n",
    "\n",
    "root_name = root_name + \"allhlcn18\"\n",
    "\n",
    "quarter = [\"1\",\"2\",\"3\",\"4\"]\n",
    "\n",
    "for item in quarter:\n",
    "    \n",
    "    file_name = root_name + item + \".xlsx\"\n",
    "    \n",
    "    df = df.append(clean_bls_quarter(file_name,empl_time_dict_18))\n",
    "    \n",
    "############################################################################  \n",
    "root_name = cwd + \"\\\\bls_files\\\\\"\n",
    "\n",
    "root_name = root_name + \"allhlcn19\"\n",
    "\n",
    "quarter = [\"1\"]\n",
    "\n",
    "for item in quarter:\n",
    "    \n",
    "    file_name = root_name + item + \".xlsx\"\n",
    "    \n",
    "    df = df.append(clean_bls_quarter(file_name,empl_time_dict_19))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values([\"area_fips\", \"time\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_employ = trade_data.merge(df, left_index = True, right_index = True, how = \"right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trade_employ.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#file_path = os.getcwd() + \"\\\\data\\\\trade_employment_goods.parquet\"\n",
    "\n",
    "#pq.write_table(pa.Table.from_pandas(trade_employ.reset_index()), file_path)\n",
    "\n",
    "file_path = os.getcwd() + \"\\\\data\\\\trade_employment_all.parquet\"\n",
    "\n",
    "pq.write_table(pa.Table.from_pandas(trade_employ.reset_index()), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_employ.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_employ.head(25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
