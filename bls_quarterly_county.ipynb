{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\linearmodels\\panel\\data.py:10: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import (Categorical, DataFrame, Index, MultiIndex, Panel, Series,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd             # data package\n",
    "import matplotlib.pyplot as plt # graphics \n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "import requests, io             # internet and input tools  \n",
    "import zipfile as zf            # zip file tools \n",
    "import os  \n",
    "\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "from linearmodels.iv import IV2SLS\n",
    "from linearmodels.panel import PanelOLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview. \n",
    "\n",
    "This file essentially grabs the month by county files from the [Quarterly Census of Employment and Wages](https://www.bls.gov/cew/) files from the BLS and then creates employment measures at the county-level, monthly frequency. A couple of comments about the code:\n",
    "\n",
    "   - In the funciton ``clean_bls_quarter`` there is a line to be uncommented or not depending upon if I want a dataset with goods employment or total employment. Future enhancements of this notebook should just return one dataframe with both.\n",
    "    \n",
    "    \n",
    "   - It can accomadate the 2016 data (and further back if modified). Currently it just uses the 2017, 2018, and 2019 (which only have Q1 values. See the relese calander when updates will be made.\n",
    "   \n",
    "### Step 1\n",
    "\n",
    "Bring in the trade/tariff data for which we will merge stuff...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "\n",
    "trade_data = pq.read_table(cwd + \"\\\\data\\\\total_trade_data.parquet\").to_pandas()\n",
    "\n",
    "trade_data[\"time\"] = pd.to_datetime(trade_data.time)\n",
    "\n",
    "trade_data.set_index([\"area_fips\", \"time\"],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.4691811550724125"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_data.head()\n",
    "\n",
    "exposure = pd.qcut(trade_data.xs('2018-12-1', level=1).tariff, 4 ,labels = False)\n",
    "\n",
    "most_exposed = exposure[exposure == 3].index.tolist()\n",
    "\n",
    "trade_data.loc[most_exposed].xs('2018-12-1', level=1).tariff.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is ultra-clunky. Should fix in the future. But it takes names (which is how the BLS files are written) and then will map them into a datatime value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = [14,15,16,17,18,19]\n",
    "\n",
    "empl_time_dict = {}\n",
    "\n",
    "foo = 0\n",
    "\n",
    "for xxx in years:\n",
    "    \n",
    "    \n",
    "    year = int(\"20\" + str(xxx))\n",
    "    \n",
    "    \n",
    "    empl_time_dict[\"year_{0}\".format(year)] = {\"January Employment\":dt.datetime(year,1,1),\n",
    "                 \"February Employment\":dt.datetime(year,2,1),\n",
    "                 \"March Employment\":dt.datetime(year,3,1),\n",
    "                 \"April Employment\":dt.datetime(year,4,1),\n",
    "                 \"May Employment\":dt.datetime(year,5,1),\n",
    "                 \"June Employment\":dt.datetime(year,6,1),\n",
    "                 \"July Employment\":dt.datetime(year,7,1),\n",
    "                 \"August Employment\":dt.datetime(year,8,1),\n",
    "                 \"September Employment\":dt.datetime(year,9,1),\n",
    "                 \"October Employment\":dt.datetime(year,10,1),\n",
    "                 \"November Employment\":dt.datetime(year,11,1),\n",
    "                 \"December Employment\":dt.datetime(year,12,1),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'January Employment': datetime.datetime(2014, 1, 1, 0, 0),\n",
       " 'February Employment': datetime.datetime(2014, 2, 1, 0, 0),\n",
       " 'March Employment': datetime.datetime(2014, 3, 1, 0, 0),\n",
       " 'April Employment': datetime.datetime(2014, 4, 1, 0, 0),\n",
       " 'May Employment': datetime.datetime(2014, 5, 1, 0, 0),\n",
       " 'June Employment': datetime.datetime(2014, 6, 1, 0, 0),\n",
       " 'July Employment': datetime.datetime(2014, 7, 1, 0, 0),\n",
       " 'August Employment': datetime.datetime(2014, 8, 1, 0, 0),\n",
       " 'September Employment': datetime.datetime(2014, 9, 1, 0, 0),\n",
       " 'October Employment': datetime.datetime(2014, 10, 1, 0, 0),\n",
       " 'November Employment': datetime.datetime(2014, 11, 1, 0, 0),\n",
       " 'December Employment': datetime.datetime(2014, 12, 1, 0, 0)}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "empl_time_dict[\"year_2014\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "clistQ1 = ['Area\\nCode','NAICS','Qtr','January Employment', 'February Employment',\n",
    "       'March Employment', 'Total Quarterly Wages', 'Average Weekly Wage','Own',\"Area Type\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Download\n",
    "\n",
    "This downloads the ``.zip`` files for which we can grab the data. They are all in excell format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://data.bls.gov/cew/data/files/2014/xls/2014_all_county_high_level.zip\"\n",
    "# This will read in the annual, single file. It's big, but has all we want...\n",
    "\n",
    "r = requests.get(url) \n",
    "\n",
    "# convert bytes to zip file  \n",
    "bls_q2014 = zf.ZipFile(io.BytesIO(r.content)) \n",
    "bls_q2014.extractall(cwd + \"\\\\bls_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://data.bls.gov/cew/data/files/2015/xls/2015_all_county_high_level.zip\"\n",
    "# This will read in the annual, single file. It's big, but has all we want...\n",
    "\n",
    "r = requests.get(url) \n",
    "\n",
    "# convert bytes to zip file  \n",
    "bls_q2015 = zf.ZipFile(io.BytesIO(r.content)) \n",
    "bls_q2015.extractall(cwd + \"\\\\bls_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://data.bls.gov/cew/data/files/2016/xls/2016_all_county_high_level.zip\"\n",
    "# This will read in the annual, single file. It's big, but has all we want...\n",
    "\n",
    "r = requests.get(url) \n",
    "\n",
    "# convert bytes to zip file  \n",
    "bls_q2016 = zf.ZipFile(io.BytesIO(r.content)) \n",
    "bls_q2016.extractall(cwd + \"\\\\bls_files\")\n",
    "\n",
    "url = \"https://data.bls.gov/cew/data/files/2017/xls/2017_all_county_high_level.zip\"\n",
    "# This will read in the annual, single file. It's big, but has all we want...\n",
    "\n",
    "r = requests.get(url) \n",
    "\n",
    "# convert bytes to zip file  \n",
    "bls_q2017 = zf.ZipFile(io.BytesIO(r.content)) \n",
    "bls_q2017.extractall(cwd + \"\\\\bls_files\")\n",
    "\n",
    "url = \"https://data.bls.gov/cew/data/files/2018/xls/2018_all_county_high_level.zip\"\n",
    "\n",
    "r = requests.get(url) \n",
    "\n",
    "bls_q2018 = zf.ZipFile(io.BytesIO(r.content)) \n",
    "bls_q2018.extractall(cwd + \"\\\\bls_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://data.bls.gov/cew/data/files/2019/xls/2019_all_county_high_level.zip\"\n",
    "\n",
    "r = requests.get(url) \n",
    "\n",
    "bls_q2019 = zf.ZipFile(io.BytesIO(r.content)) \n",
    "bls_q2019.extractall(cwd + \"\\\\bls_files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ZipInfo filename='allhlcn191.xlsx' compress_type=deflate external_attr=0x20 file_size=6839716 compress_size=6715278>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bls_q2019.filelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ### Step 3: Clean and Shape it\n",
    "   \n",
    "   Below is a function that takes in an excell sheet and does what we want to it. Then below we will work through a for loop over all the sheets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bls_quarter_cat(df,cat,var_name, time_dict):\n",
    "    \n",
    "    # Take only private\n",
    "\n",
    "    df = df[df[\"Own\"] == 5] \n",
    "\n",
    "# Take aggregate\n",
    "\n",
    "    #df = df[df[\"NAICS\"] == 101] # Take goods producing \n",
    "    \n",
    "    df = df[df[\"NAICS\"] == cat] # Take all employment in all sectors\n",
    "\n",
    "# Take only counties \n",
    "    df = df[df[\"Area Type\"] == \"County\"] \n",
    "\n",
    "    df.rename({\"Area\\nCode\": \"GEOFIPS\"},axis = 1, inplace = True)\n",
    "\n",
    "    df[\"GEOFIPS\"] = df[\"GEOFIPS\"].astype(int)\n",
    "\n",
    "    df.set_index(\"GEOFIPS\", inplace = True)\n",
    "\n",
    "    df = df.reindex(trade_data.index.get_level_values(0).unique().astype(int).tolist())\n",
    "\n",
    "    df = df.iloc[:,[13,14,15]].reset_index()\n",
    "    # This grabs only values we want, i.e. the employment for that quarter. So for example,\n",
    "    # in Q1, 13 = January, 14 = Febuary, 15 = March. And so forth for Q2...\n",
    "\n",
    "    df = df.melt(\"GEOFIPS\")\n",
    "\n",
    "    df.replace(time_dict,inplace = True)\n",
    "\n",
    "    df.rename({\"variable\":\"time\", \"value\": var_name, \"GEOFIPS\": \"area_fips\"}, axis = 1, inplace = True)\n",
    "    \n",
    "    df[\"area_fips\"] = df[\"area_fips\"].astype(str)\n",
    "    \n",
    "    df.set_index([\"area_fips\", \"time\"], inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_bls_quarter(excell_sheet, time_dict):\n",
    "\n",
    "    foo = pd.read_excel(excell_sheet, sheet_name = \"US_St_Cn_MSA\")\n",
    "    \n",
    "    naics_cats = [10,101]\n",
    "    \n",
    "    var_name = {10: \"emp_all\", 101:\"emp_gds\"}\n",
    "    \n",
    "    cat_dict = {}\n",
    "    \n",
    "    for xxx in naics_cats:\n",
    "        \n",
    "        foo_df = bls_quarter_cat(foo, xxx, var_name[xxx], time_dict)\n",
    "        \n",
    "        cat_dict[\"cat_{0}\".format(xxx)] = foo_df\n",
    "                \n",
    "    df = cat_dict[\"cat_10\"].merge(cat_dict[\"cat_101\"], left_index = True, right_index = True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then given the function above, work through the file list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([])\n",
    "\n",
    "############################################################################\n",
    "root_name = cwd + \"\\\\bls_files\\\\\"\n",
    "\n",
    "root_name = root_name + \"allhlcn14\"\n",
    "\n",
    "quarter = [\"1\",\"2\",\"3\",\"4\"]\n",
    "\n",
    "for item in quarter:\n",
    "    \n",
    "    file_name = root_name + item + \".xlsx\"\n",
    "    \n",
    "    df = df.append(clean_bls_quarter(file_name,empl_time_dict[\"year_2014\"]))\n",
    "\n",
    "############################################################################\n",
    "root_name = cwd + \"\\\\bls_files\\\\\"\n",
    "\n",
    "root_name = root_name + \"allhlcn15\"\n",
    "\n",
    "quarter = [\"1\",\"2\",\"3\",\"4\"]\n",
    "\n",
    "for item in quarter:\n",
    "    \n",
    "    file_name = root_name + item + \".xlsx\"\n",
    "    \n",
    "    df = df.append(clean_bls_quarter(file_name,empl_time_dict[\"year_2015\"]))\n",
    "\n",
    "############################################################################\n",
    "\n",
    "root_name = cwd + \"\\\\bls_files\\\\\"\n",
    "\n",
    "root_name = root_name + \"allhlcn16\"\n",
    "\n",
    "quarter = [\"1\",\"2\",\"3\",\"4\"]\n",
    "\n",
    "for item in quarter:\n",
    "    \n",
    "    file_name = root_name + item + \".xlsx\"\n",
    "    \n",
    "    df = df.append(clean_bls_quarter(file_name,empl_time_dict[\"year_2016\"]))\n",
    "    \n",
    "############################################################################\n",
    "\n",
    "root_name = cwd + \"\\\\bls_files\\\\\"\n",
    "\n",
    "root_name = root_name + \"allhlcn17\"\n",
    "\n",
    "quarter = [\"1\",\"2\",\"3\",\"4\"]\n",
    "\n",
    "for item in quarter:\n",
    "    \n",
    "    file_name = root_name + item + \".xlsx\"\n",
    "    \n",
    "    df = df.append(clean_bls_quarter(file_name,empl_time_dict[\"year_2017\"]))\n",
    "    \n",
    "############################################################################  \n",
    "root_name = cwd + \"\\\\bls_files\\\\\"\n",
    "\n",
    "root_name = root_name + \"allhlcn18\"\n",
    "\n",
    "quarter = [\"1\",\"2\",\"3\",\"4\"]\n",
    "\n",
    "for item in quarter:\n",
    "    \n",
    "    file_name = root_name + item + \".xlsx\"\n",
    "    \n",
    "    df = df.append(clean_bls_quarter(file_name,empl_time_dict[\"year_2018\"]))\n",
    "    \n",
    "############################################################################  \n",
    "root_name = cwd + \"\\\\bls_files\\\\\"\n",
    "\n",
    "root_name = root_name + \"allhlcn19\"\n",
    "\n",
    "quarter = [\"1\"]\n",
    "\n",
    "for item in quarter:\n",
    "    \n",
    "    file_name = root_name + item + \".xlsx\"\n",
    "    \n",
    "    df = df.append(clean_bls_quarter(file_name,empl_time_dict[\"year_2019\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then just checksome stuff, reshape, then save for the analysis part. Note how this is working (again clunky), if you want the goods employment, uncomment out that. If you want total employment do the other one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values([\"area_fips\", \"time\"], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "emp_all    float64\n",
       "emp_gds    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.loc[\"10003\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_employ = trade_data.merge(df, left_index = True, right_index = True, how = \"right\")\n",
    "# This is a place to be mindfull about time period, if we want \n",
    "# do left if you just want to conform with the trade data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trade_employ.total_employment.fillna(method='bfill', inplace = True)\n",
    "\n",
    "trade_employ.tariff.fillna(method='bfill', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfrural = pd.read_excel(\"https://www2.census.gov/geo/docs/reference/ua/County_Rural_Lookup.xlsx\", skiprows=[0,1,2],\n",
    "                       nrows = 3142)\n",
    "\n",
    "dfrural[\"area_fips\"] = dfrural[\"2015 GEOID\"].astype(int)\n",
    "\n",
    "trade_employ.reset_index(inplace = True)\n",
    "\n",
    "trade_employ[\"area_fips\"] = trade_employ[\"area_fips\"].astype(int)\n",
    "\n",
    "trade_employ = trade_employ.merge(dfrural[[\"area_fips\", \"2010 Census \\nPercent Rural\",\n",
    "                             \"2010 Census Total Population\"]], left_on = \"area_fips\", right_on = \"area_fips\")\n",
    "\n",
    "trade_employ.set_index([\"area_fips\", \"time\"],inplace = True)\n",
    "\n",
    "trade_employ.rename({\"2010 Census \\nPercent Rural\": \"rural_share\",\n",
    "            \"2010 Census Total Population\": \"population\"}, inplace = True, axis = 1)\n",
    "\n",
    "trade_employ[\"rural_share\"] = 0.01*trade_employ[\"rural_share\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.getcwd() + \"\\\\data\\\\trade_employment_2014.parquet\"\n",
    "\n",
    "pq.write_table(pa.Table.from_pandas(trade_employ.reset_index()), file_path)\n",
    "\n",
    "#file_path = os.getcwd() + \"\\\\data\\\\trade_employment_all.parquet\"\n",
    "\n",
    "#pq.write_table(pa.Table.from_pandas(trade_employ.reset_index()), file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "total_exp_pc        float64\n",
       "china_exp_pc        float64\n",
       "tariff              float64\n",
       "emplvl_2017         float64\n",
       "fips                 object\n",
       "total_employment    float64\n",
       "emp_all             float64\n",
       "emp_gds             float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_employ.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_exp_pc</th>\n",
       "      <th>china_exp_pc</th>\n",
       "      <th>tariff</th>\n",
       "      <th>emplvl_2017</th>\n",
       "      <th>fips</th>\n",
       "      <th>total_employment</th>\n",
       "      <th>emp_all</th>\n",
       "      <th>emp_gds</th>\n",
       "      <th>rural_share</th>\n",
       "      <th>population</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2014-01-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.211322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>249775.0</td>\n",
       "      <td>237770.0</td>\n",
       "      <td>23235.0</td>\n",
       "      <td>0.046024</td>\n",
       "      <td>538479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014-02-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.211322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>249775.0</td>\n",
       "      <td>235894.0</td>\n",
       "      <td>23115.0</td>\n",
       "      <td>0.046024</td>\n",
       "      <td>538479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014-03-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.211322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>249775.0</td>\n",
       "      <td>237947.0</td>\n",
       "      <td>23535.0</td>\n",
       "      <td>0.046024</td>\n",
       "      <td>538479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014-04-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.211322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>249775.0</td>\n",
       "      <td>240968.0</td>\n",
       "      <td>23990.0</td>\n",
       "      <td>0.046024</td>\n",
       "      <td>538479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2014-05-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.211322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>249775.0</td>\n",
       "      <td>243356.0</td>\n",
       "      <td>24490.0</td>\n",
       "      <td>0.046024</td>\n",
       "      <td>538479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-11-01</td>\n",
       "      <td>516.246195</td>\n",
       "      <td>37.360160</td>\n",
       "      <td>0.456547</td>\n",
       "      <td>9072.0</td>\n",
       "      <td>10003</td>\n",
       "      <td>249775.0</td>\n",
       "      <td>259963.0</td>\n",
       "      <td>26256.0</td>\n",
       "      <td>0.046024</td>\n",
       "      <td>538479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2018-12-01</td>\n",
       "      <td>499.745029</td>\n",
       "      <td>39.971812</td>\n",
       "      <td>0.456547</td>\n",
       "      <td>9072.0</td>\n",
       "      <td>10003</td>\n",
       "      <td>249775.0</td>\n",
       "      <td>260304.0</td>\n",
       "      <td>26435.0</td>\n",
       "      <td>0.046024</td>\n",
       "      <td>538479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-01-01</td>\n",
       "      <td>496.613756</td>\n",
       "      <td>34.459205</td>\n",
       "      <td>0.448531</td>\n",
       "      <td>9072.0</td>\n",
       "      <td>10003</td>\n",
       "      <td>249775.0</td>\n",
       "      <td>253387.0</td>\n",
       "      <td>25940.0</td>\n",
       "      <td>0.046024</td>\n",
       "      <td>538479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>485.506472</td>\n",
       "      <td>35.747547</td>\n",
       "      <td>0.448519</td>\n",
       "      <td>9072.0</td>\n",
       "      <td>10003</td>\n",
       "      <td>249775.0</td>\n",
       "      <td>252503.0</td>\n",
       "      <td>25814.0</td>\n",
       "      <td>0.046024</td>\n",
       "      <td>538479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2019-03-01</td>\n",
       "      <td>552.995665</td>\n",
       "      <td>47.108656</td>\n",
       "      <td>0.448519</td>\n",
       "      <td>9072.0</td>\n",
       "      <td>10003</td>\n",
       "      <td>249775.0</td>\n",
       "      <td>254122.0</td>\n",
       "      <td>26245.0</td>\n",
       "      <td>0.046024</td>\n",
       "      <td>538479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            total_exp_pc  china_exp_pc    tariff  emplvl_2017   fips  \\\n",
       "time                                                                   \n",
       "2014-01-01           NaN           NaN  0.211322          NaN    NaN   \n",
       "2014-02-01           NaN           NaN  0.211322          NaN    NaN   \n",
       "2014-03-01           NaN           NaN  0.211322          NaN    NaN   \n",
       "2014-04-01           NaN           NaN  0.211322          NaN    NaN   \n",
       "2014-05-01           NaN           NaN  0.211322          NaN    NaN   \n",
       "...                  ...           ...       ...          ...    ...   \n",
       "2018-11-01    516.246195     37.360160  0.456547       9072.0  10003   \n",
       "2018-12-01    499.745029     39.971812  0.456547       9072.0  10003   \n",
       "2019-01-01    496.613756     34.459205  0.448531       9072.0  10003   \n",
       "2019-02-01    485.506472     35.747547  0.448519       9072.0  10003   \n",
       "2019-03-01    552.995665     47.108656  0.448519       9072.0  10003   \n",
       "\n",
       "            total_employment   emp_all  emp_gds  rural_share  population  \n",
       "time                                                                      \n",
       "2014-01-01          249775.0  237770.0  23235.0     0.046024      538479  \n",
       "2014-02-01          249775.0  235894.0  23115.0     0.046024      538479  \n",
       "2014-03-01          249775.0  237947.0  23535.0     0.046024      538479  \n",
       "2014-04-01          249775.0  240968.0  23990.0     0.046024      538479  \n",
       "2014-05-01          249775.0  243356.0  24490.0     0.046024      538479  \n",
       "...                      ...       ...      ...          ...         ...  \n",
       "2018-11-01          249775.0  259963.0  26256.0     0.046024      538479  \n",
       "2018-12-01          249775.0  260304.0  26435.0     0.046024      538479  \n",
       "2019-01-01          249775.0  253387.0  25940.0     0.046024      538479  \n",
       "2019-02-01          249775.0  252503.0  25814.0     0.046024      538479  \n",
       "2019-03-01          249775.0  254122.0  26245.0     0.046024      538479  \n",
       "\n",
       "[63 rows x 10 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trade_employ.loc[10003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
